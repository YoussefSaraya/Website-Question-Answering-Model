{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CM9hMkmE4z_m"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "# from bs4 import BeautifulSoup # Uncomment if needed for HTML stripping\n",
        "from google.colab import drive # Import drive library\n",
        "import os # To check if path exists"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    drive.mount('/content/drive')\n",
        "    print(\"Google Drive mounted successfully.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error mounting Google Drive: {e}\")\n",
        "    print(\"Please ensure you authorize Colab to access your Drive.\")\n",
        "    exit()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sD4jIq4uEpfV",
        "outputId": "6c252dfb-f291-41d6-cfe6-fd121c7420d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Google Drive mounted successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "# from bs4 import BeautifulSoup # Uncomment if needed for HTML stripping\n",
        "\n",
        "drive_base_path = '/content/drive/MyDrive/Web Scraping /'\n",
        "input_csv_file = os.path.join(drive_base_path, 'egypt_institutions_programs_flattened_with_amenities.csv')\n",
        "output_csv_file = ('egypt_institutions_programs_cleaned.csv') # Saving cleaned file back to Drive\n",
        "\n",
        "try:\n",
        "    # Read the CSV into a Pandas DataFrame, SPECIFYING UTF-8 ENCODING\n",
        "    df = pd.read_csv(input_csv_file, encoding='utf-8') # <--- ADD encoding='utf-8'\n",
        "    print(f\"Successfully loaded {len(df)} rows from {input_csv_file}\")\n",
        "    print(\"Initial DataFrame info:\")\n",
        "    df.info()\n",
        "    print(\"\\nSample rows before cleaning (should show correct Arabic now):\")\n",
        "    print(df.head())\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error loading CSV: {e}\")\n",
        "    # If you get a UnicodeDecodeError here, the file might NOT be UTF-8.\n",
        "    # You could try 'latin-1' or 'windows-1252' to see if it loads without error,\n",
        "    # but the Mojibake would persist, meaning the *source* file needs fixing or Solution 2.\n",
        "    print(\"If you encountered a UnicodeDecodeError, the source CSV might not be UTF-8 encoded.\")\n",
        "    exit()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V96G0RjgEte7",
        "outputId": "295ac67f-0a7c-4660-c8b9-b42b4411ca40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully loaded 17581 rows from /content/drive/MyDrive/Web Scraping /egypt_institutions_programs_flattened_with_amenities.csv\n",
            "Initial DataFrame info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 17581 entries, 0 to 17580\n",
            "Data columns (total 23 columns):\n",
            " #   Column                   Non-Null Count  Dtype  \n",
            "---  ------                   --------------  -----  \n",
            " 0   University               17581 non-null  object \n",
            " 1   Category                 17581 non-null  object \n",
            " 2   Year Built               17581 non-null  object \n",
            " 3   Description              17581 non-null  object \n",
            " 4   Location                 17532 non-null  object \n",
            " 5   Phone                    17581 non-null  object \n",
            " 6   Email                    17581 non-null  object \n",
            " 7   Coordinator              15303 non-null  object \n",
            " 8   Amenities                17581 non-null  object \n",
            " 9   Detail Page URL          17581 non-null  object \n",
            " 10  Program Category         17353 non-null  object \n",
            " 11  Faculty                  17353 non-null  object \n",
            " 12  Program Name             17340 non-null  object \n",
            " 13  Program Description      16091 non-null  object \n",
            " 14  Years Of Study           13298 non-null  float64\n",
            " 15  Number Of Semesters      11156 non-null  float64\n",
            " 16  Fee In USD               14958 non-null  float64\n",
            " 17  Fee In EGP               3333 non-null   float64\n",
            " 18  Prerequisites            4106 non-null   object \n",
            " 19  Credit Hours             2753 non-null   float64\n",
            " 20  Max Study Years          10907 non-null  float64\n",
            " 21  Affiliated Universities  32 non-null     object \n",
            " 22  Semesters Abroad         20 non-null     float64\n",
            "dtypes: float64(7), object(16)\n",
            "memory usage: 3.1+ MB\n",
            "\n",
            "Sample rows before cleaning (should show correct Arabic now):\n",
            "                                          University           Category  \\\n",
            "0  Cairo Higher Institute for Languages, Interpre...     High institute   \n",
            "1                           Ain Shams University ASU  Public university   \n",
            "2                           Ain Shams University ASU  Public university   \n",
            "3                           Ain Shams University ASU  Public university   \n",
            "4                           Ain Shams University ASU  Public university   \n",
            "\n",
            "  Year Built                                        Description  \\\n",
            "0  Not Found                                      None Provided   \n",
            "1       1950  Ain Shams University is the third Egyptian uni...   \n",
            "2       1950  Ain Shams University is the third Egyptian uni...   \n",
            "3       1950  Ain Shams University is the third Egyptian uni...   \n",
            "4       1950  Ain Shams University is the third Egyptian uni...   \n",
            "\n",
            "                                            Location        Phone  \\\n",
            "0  Mokattam - the commercial station - 5 Street 5...  202 5081600   \n",
            "1  El-Khalifa El-Maamoun Street, El-Abbassia, 115...  20226831474   \n",
            "2  El-Khalifa El-Maamoun Street, El-Abbassia, 115...  20226831474   \n",
            "3  El-Khalifa El-Maamoun Street, El-Abbassia, 115...  20226831474   \n",
            "4  El-Khalifa El-Maamoun Street, El-Abbassia, 115...  20226831474   \n",
            "\n",
            "             Email               Coordinator  \\\n",
            "0  info@chi-eg.com                       NaN   \n",
            "1  info@asu.edu.eg  Prof. Sherweit El-Ahmady   \n",
            "2  info@asu.edu.eg  Prof. Sherweit El-Ahmady   \n",
            "3  info@asu.edu.eg  Prof. Sherweit El-Ahmady   \n",
            "4  info@asu.edu.eg  Prof. Sherweit El-Ahmady   \n",
            "\n",
            "                                           Amenities  \\\n",
            "0                                        None Listed   \n",
            "1  ATM and Banking Services - Accounting unit for...   \n",
            "2  ATM and Banking Services - Accounting unit for...   \n",
            "3  ATM and Banking Services - Accounting unit for...   \n",
            "4  ATM and Banking Services - Accounting unit for...   \n",
            "\n",
            "                                     Detail Page URL  ...  \\\n",
            "0  https://study-in-egypt.gov.eg/categories/All/2...  ...   \n",
            "1  https://study-in-egypt.gov.eg/categories/All/8...  ...   \n",
            "2  https://study-in-egypt.gov.eg/categories/All/8...  ...   \n",
            "3  https://study-in-egypt.gov.eg/categories/All/8...  ...   \n",
            "4  https://study-in-egypt.gov.eg/categories/All/8...  ...   \n",
            "\n",
            "                                 Program Description Years Of Study  \\\n",
            "0                                                NaN            NaN   \n",
            "1                          Study language is English            5.0   \n",
            "2        Bachelor’s degree - Pharmaceutical Sciences            6.0   \n",
            "3  Bachelor's degree - Pharmaceutical Sciences - ...            6.0   \n",
            "4      Bachelor’s degree of Oral and Dental Medicine            5.0   \n",
            "\n",
            "  Number Of Semesters Fee In USD  Fee In EGP  Prerequisites  Credit Hours  \\\n",
            "0                 NaN        NaN         NaN            NaN           NaN   \n",
            "1                10.0     6000.0         NaN            NaN           NaN   \n",
            "2                 NaN     5000.0         NaN            NaN           NaN   \n",
            "3                 NaN     5000.0         NaN            NaN           NaN   \n",
            "4                 NaN     6000.0         NaN            NaN           NaN   \n",
            "\n",
            "   Max Study Years Affiliated Universities  Semesters Abroad  \n",
            "0              NaN                     NaN               NaN  \n",
            "1              NaN                     NaN               NaN  \n",
            "2              NaN                     NaN               NaN  \n",
            "3              NaN                     NaN               NaN  \n",
            "4              NaN                     NaN               NaN  \n",
            "\n",
            "[5 rows x 23 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# List of strings to consider as 'missing'\n",
        "missing_markers = ['N/A', 'Not Found', 'None Listed', 'None Provided', '', 'Error: Missing Detail URL', 'Error: Request Timeout', 'Error: HTTP Request Failed'] # Add any other markers you see\n",
        "\n",
        "# Convert specific columns or all object columns\n",
        "for col in df.select_dtypes(include='object').columns: # Iterate through string columns\n",
        "    # Replace markers with NaN first, then fill NaN with empty string\n",
        "    df[col] = df[col].replace(missing_markers, pd.NA, regex=False)\n",
        "    df[col] = df[col].fillna('')\n",
        "print(\"\\nStandardized missing markers.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9UV6krBwE4TF",
        "outputId": "21e76119-6d0d-424a-e36b-af6a71ad87ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Standardized missing markers.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_columns_to_clean = [\n",
        "    'Name', 'Category', 'Description', 'Location', 'Coordinator', 'Amenities',\n",
        "    'Program Category', 'Faculty', 'Program Name', 'Program Description', 'Prerequisites',\n",
        "    'Affiliated Universities' # Add any other relevant text columns\n",
        "]\n",
        "\n",
        "def clean_text(text):\n",
        "    if pd.isna(text) or text == '':\n",
        "        return ''\n",
        "    text = str(text)\n",
        "    # Optional: Strip lingering HTML tags (if necessary)\n",
        "    # soup = BeautifulSoup(text, \"lxml\")\n",
        "    # text = soup.get_text()\n",
        "\n",
        "    # Normalize whitespace: replace multiple spaces/newlines/tabs with a single space\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    # Trim leading/trailing whitespace\n",
        "    text = text.strip()\n",
        "    # Optional: Remove specific unwanted characters (example: remove control characters)\n",
        "    text = re.sub(r'[\\x00-\\x1f\\x7f]', '', text)\n",
        "    # Optional: Normalize Unicode characters (helps with different quote types etc.)\n",
        "    # import unicodedata\n",
        "    # text = unicodedata.normalize('NFKC', text)\n",
        "    return text\n",
        "\n",
        "for col in text_columns_to_clean:\n",
        "    if col in df.columns:\n",
        "        print(f\"Cleaning column: {col}\")\n",
        "        df[col] = df[col].apply(clean_text)\n",
        "    else:\n",
        "        print(f\"Warning: Column '{col}' not found for cleaning.\")\n",
        "print(\"\\nPerformed whitespace and basic text cleaning.\")\n",
        "\n",
        "# Special handling for Amenities to keep newlines if desired for readability later,\n",
        "# but still clean excess whitespace around them.\n",
        "if 'Amenities' in df.columns:\n",
        "    def clean_amenities(text):\n",
        "         if pd.isna(text) or text == '': return ''\n",
        "         lines = text.split('\\n')\n",
        "         cleaned_lines = [' '.join(line.split()).strip() for line in lines if line.strip()]\n",
        "         return \"\\n\".join(cleaned_lines) # Re-join with single newline\n",
        "    df['Amenities'] = df['Amenities'].apply(clean_amenities)\n",
        "    print(\"Performed specific newline cleaning for Amenities.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "STzZr4n-F4iy",
        "outputId": "73f5f96b-13b8-40ef-ee04-0db4a94c9937"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Column 'Name' not found for cleaning.\n",
            "Cleaning column: Category\n",
            "Cleaning column: Description\n",
            "Cleaning column: Location\n",
            "Cleaning column: Coordinator\n",
            "Cleaning column: Amenities\n",
            "Cleaning column: Program Category\n",
            "Cleaning column: Faculty\n",
            "Cleaning column: Program Name\n",
            "Cleaning column: Program Description\n",
            "Cleaning column: Prerequisites\n",
            "Cleaning column: Affiliated Universities\n",
            "\n",
            "Performed whitespace and basic text cleaning.\n",
            "Performed specific newline cleaning for Amenities.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "numeric_columns = [\n",
        "    'Year Built', 'Fee In USD', 'Fee In EGP', 'Years Of Study', 'Number Of Semesters',\n",
        "    'Credit Hours', 'Max Study Years', 'Semesters Abroad'\n",
        "]\n",
        "\n",
        "def extract_and_convert_numeric(value):\n",
        "    if pd.isna(value) or value == '':\n",
        "        return None # Use None for missing numbers (will become NaN in numeric columns)\n",
        "    # Try extracting the first sequence of digits (possibly with decimal)\n",
        "    # Remove commas, $, etc. first\n",
        "    cleaned_value = re.sub(r'[$,]', '', str(value))\n",
        "    # Find the first number-like pattern (integer or float)\n",
        "    match = re.search(r'\\d+(\\.\\d+)?', cleaned_value)\n",
        "    if match:\n",
        "        try:\n",
        "            num_str = match.group(0)\n",
        "            # Decide if it should be integer or float\n",
        "            if '.' in num_str:\n",
        "                return float(num_str)\n",
        "            else:\n",
        "                return int(num_str)\n",
        "        except ValueError:\n",
        "            return None # Conversion failed\n",
        "    else:\n",
        "        return None # No number found\n",
        "\n",
        "for col in numeric_columns:\n",
        "    if col in df.columns:\n",
        "        print(f\"Converting column to numeric: {col}\")\n",
        "        df[col] = df[col].apply(extract_and_convert_numeric)\n",
        "        # Optionally convert integer columns after processing NAs\n",
        "        if df[col].notna().all() and all(df[col] % 1 == 0):\n",
        "             # Check if convertible to nullable Int64\n",
        "             try:\n",
        "                df[col] = df[col].astype('Int64')\n",
        "             except Exception:\n",
        "                pass # Keep as float if conversion fails\n",
        "    else:\n",
        "         print(f\"Warning: Column '{col}' not found for numeric conversion.\")\n",
        "print(\"\\nPerformed numeric conversion.\")\n",
        "df.info() # Check dtypes after conversion"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eQsa-F8eF7QO",
        "outputId": "c7ba47f9-4ebc-497b-e21b-75e207fad4b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converting column to numeric: Year Built\n",
            "Converting column to numeric: Fee In USD\n",
            "Converting column to numeric: Fee In EGP\n",
            "Converting column to numeric: Years Of Study\n",
            "Converting column to numeric: Number Of Semesters\n",
            "Converting column to numeric: Credit Hours\n",
            "Converting column to numeric: Max Study Years\n",
            "Converting column to numeric: Semesters Abroad\n",
            "\n",
            "Performed numeric conversion.\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 17581 entries, 0 to 17580\n",
            "Data columns (total 23 columns):\n",
            " #   Column                   Non-Null Count  Dtype  \n",
            "---  ------                   --------------  -----  \n",
            " 0   University               17581 non-null  object \n",
            " 1   Category                 17581 non-null  object \n",
            " 2   Year Built               17180 non-null  float64\n",
            " 3   Description              17581 non-null  object \n",
            " 4   Location                 17581 non-null  object \n",
            " 5   Phone                    17581 non-null  object \n",
            " 6   Email                    17581 non-null  object \n",
            " 7   Coordinator              17581 non-null  object \n",
            " 8   Amenities                17581 non-null  object \n",
            " 9   Detail Page URL          17581 non-null  object \n",
            " 10  Program Category         17581 non-null  object \n",
            " 11  Faculty                  17581 non-null  object \n",
            " 12  Program Name             17581 non-null  object \n",
            " 13  Program Description      17581 non-null  object \n",
            " 14  Years Of Study           13298 non-null  float64\n",
            " 15  Number Of Semesters      11156 non-null  float64\n",
            " 16  Fee In USD               14958 non-null  float64\n",
            " 17  Fee In EGP               3333 non-null   float64\n",
            " 18  Prerequisites            17581 non-null  object \n",
            " 19  Credit Hours             2753 non-null   float64\n",
            " 20  Max Study Years          10907 non-null  float64\n",
            " 21  Affiliated Universities  17581 non-null  object \n",
            " 22  Semesters Abroad         20 non-null     float64\n",
            "dtypes: float64(8), object(15)\n",
            "memory usage: 3.1+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nSample rows after cleaning:\")\n",
        "print(df.head())\n",
        "\n",
        "# Optional: Check for columns that are now entirely empty/NA\n",
        "print(\"\\nColumns with all missing values after cleaning:\")\n",
        "print(df.columns[df.isnull().all()])\n",
        "\n",
        "# Save the cleaned DataFrame\n",
        "try:\n",
        "    df.to_csv(output_csv_file, index=False, encoding='utf-8')\n",
        "    print(f\"\\nCleaned data successfully saved to {output_csv_file}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error saving cleaned CSV: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vlLQQ30IF_b4",
        "outputId": "7a8c09a8-baa0-404a-91d4-160761d06bc7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sample rows after cleaning:\n",
            "                                          University           Category  \\\n",
            "0  Cairo Higher Institute for Languages, Interpre...     High institute   \n",
            "1                           Ain Shams University ASU  Public university   \n",
            "2                           Ain Shams University ASU  Public university   \n",
            "3                           Ain Shams University ASU  Public university   \n",
            "4                           Ain Shams University ASU  Public university   \n",
            "\n",
            "   Year Built                                        Description  \\\n",
            "0         NaN                                                      \n",
            "1      1950.0  Ain Shams University is the third Egyptian uni...   \n",
            "2      1950.0  Ain Shams University is the third Egyptian uni...   \n",
            "3      1950.0  Ain Shams University is the third Egyptian uni...   \n",
            "4      1950.0  Ain Shams University is the third Egyptian uni...   \n",
            "\n",
            "                                            Location        Phone  \\\n",
            "0  Mokattam - the commercial station - 5 Street 5...  202 5081600   \n",
            "1  El-Khalifa El-Maamoun Street, El-Abbassia, 115...  20226831474   \n",
            "2  El-Khalifa El-Maamoun Street, El-Abbassia, 115...  20226831474   \n",
            "3  El-Khalifa El-Maamoun Street, El-Abbassia, 115...  20226831474   \n",
            "4  El-Khalifa El-Maamoun Street, El-Abbassia, 115...  20226831474   \n",
            "\n",
            "             Email               Coordinator  \\\n",
            "0  info@chi-eg.com                             \n",
            "1  info@asu.edu.eg  Prof. Sherweit El-Ahmady   \n",
            "2  info@asu.edu.eg  Prof. Sherweit El-Ahmady   \n",
            "3  info@asu.edu.eg  Prof. Sherweit El-Ahmady   \n",
            "4  info@asu.edu.eg  Prof. Sherweit El-Ahmady   \n",
            "\n",
            "                                           Amenities  \\\n",
            "0                                                      \n",
            "1  ATM and Banking Services - Accounting unit for...   \n",
            "2  ATM and Banking Services - Accounting unit for...   \n",
            "3  ATM and Banking Services - Accounting unit for...   \n",
            "4  ATM and Banking Services - Accounting unit for...   \n",
            "\n",
            "                                     Detail Page URL  ...  \\\n",
            "0  https://study-in-egypt.gov.eg/categories/All/2...  ...   \n",
            "1  https://study-in-egypt.gov.eg/categories/All/8...  ...   \n",
            "2  https://study-in-egypt.gov.eg/categories/All/8...  ...   \n",
            "3  https://study-in-egypt.gov.eg/categories/All/8...  ...   \n",
            "4  https://study-in-egypt.gov.eg/categories/All/8...  ...   \n",
            "\n",
            "                                 Program Description Years Of Study  \\\n",
            "0                                                               NaN   \n",
            "1                          Study language is English            5.0   \n",
            "2        Bachelor’s degree - Pharmaceutical Sciences            6.0   \n",
            "3  Bachelor's degree - Pharmaceutical Sciences - ...            6.0   \n",
            "4      Bachelor’s degree of Oral and Dental Medicine            5.0   \n",
            "\n",
            "  Number Of Semesters Fee In USD  Fee In EGP  Prerequisites  Credit Hours  \\\n",
            "0                 NaN        NaN         NaN                          NaN   \n",
            "1                10.0     6000.0         NaN                          NaN   \n",
            "2                 NaN     5000.0         NaN                          NaN   \n",
            "3                 NaN     5000.0         NaN                          NaN   \n",
            "4                 NaN     6000.0         NaN                          NaN   \n",
            "\n",
            "   Max Study Years Affiliated Universities  Semesters Abroad  \n",
            "0              NaN                                       NaN  \n",
            "1              NaN                                       NaN  \n",
            "2              NaN                                       NaN  \n",
            "3              NaN                                       NaN  \n",
            "4              NaN                                       NaN  \n",
            "\n",
            "[5 rows x 23 columns]\n",
            "\n",
            "Columns with all missing values after cleaning:\n",
            "Index([], dtype='object')\n",
            "\n",
            "Cleaned data successfully saved to egypt_institutions_programs_cleaned.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === Import Necessary Libraries ===\n",
        "import pandas as pd\n",
        "import re\n",
        "from bs4 import BeautifulSoup # Keep import in case needed later, but commented out by default\n",
        "from google.colab import drive\n",
        "import os\n",
        "import logging\n",
        "\n",
        "# === Configuration ===\n",
        "# Configure logging\n",
        "LOG_FILE_CLEAN = 'data_cleaning.log' # Log file specific to this cleaning script\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(levelname)s - [%(funcName)s] %(message)s',\n",
        "    handlers=[\n",
        "        logging.FileHandler(LOG_FILE_CLEAN, mode='w', encoding='utf-8'), # Save log to file\n",
        "        logging.StreamHandler() # Also print logs to console\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Define file paths in Google Drive (Ensure the path exactly matches your Drive)\n",
        "# IMPORTANT: Note the space after 'Web Scraping ' if it exists in your folder name\n",
        "DRIVE_BASE_PATH = '/content/drive/MyDrive/Web Scraping /'\n",
        "INPUT_CSV_FILE = os.path.join(DRIVE_BASE_PATH, 'egypt_institutions_programs_flattened_with_amenities.csv')\n",
        "OUTPUT_CSV_FILE = os.path.join(DRIVE_BASE_PATH, 'egypt_institutions_programs_cleaned.csv')\n",
        "\n",
        "# Markers indicating missing or irrelevant data\n",
        "MISSING_MARKERS = [\n",
        "    'N/A', 'Not Found', 'None Listed', 'None Provided', '',\n",
        "    'Error: Missing Detail URL', 'Error: Request Timeout',\n",
        "    'Error: HTTP Request Failed', 'Error: Parsing Failed'\n",
        "    # Add any other similar markers observed in your data\n",
        "]\n",
        "\n",
        "# Columns expected to contain free text needing cleaning\n",
        "TEXT_COLUMNS_TO_CLEAN = [\n",
        "    'Name', 'Category', 'Description', 'Location', 'Coordinator', 'Amenities',\n",
        "    'Program Category', 'Faculty', 'Program Name', 'Program Description', 'Prerequisites',\n",
        "    'Affiliated Universities'\n",
        "]\n",
        "\n",
        "# Columns expected to contain numeric data\n",
        "NUMERIC_COLUMNS = [\n",
        "    'Year Built', 'Fee In USD', 'Fee In EGP', 'Years Of Study', 'Number Of Semesters',\n",
        "    'Credit Hours', 'Max Study Years', 'Semesters Abroad'\n",
        "]\n",
        "\n",
        "# === Helper Functions ===\n",
        "\n",
        "def fix_mojibake(text):\n",
        "    \"\"\"Attempts to fix Mojibake assuming UTF-8 misinterpreted as Latin-1.\"\"\"\n",
        "    if isinstance(text, str) and text: # Only process non-empty strings\n",
        "        try:\n",
        "            # Encode back to bytes using the likely WRONG encoding, then decode with CORRECT encoding\n",
        "            return text.encode('latin-1').decode('utf-8')\n",
        "        except (UnicodeEncodeError, UnicodeDecodeError):\n",
        "            # If the fix fails (e.g., text was already correct or different issue)\n",
        "            return text\n",
        "    return text # Return non-strings or empty strings as is\n",
        "\n",
        "def clean_text(text):\n",
        "    \"\"\"Cleans whitespace and optional basic character issues from a text string.\"\"\"\n",
        "    if pd.isna(text) or text == '':\n",
        "        return ''\n",
        "    text = str(text)\n",
        "    # --- Optional HTML Stripping (Uncomment if needed) ---\n",
        "    # try:\n",
        "    #     soup = BeautifulSoup(text, \"lxml\")\n",
        "    #     text = soup.get_text()\n",
        "    # except Exception as e_html:\n",
        "    #     logging.warning(f\"HTML parsing failed for text snippet: {text[:50]}... Error: {e_html}\")\n",
        "    #     # Fallback to regex or just continue if BeautifulSoup fails\n",
        "    #     text = re.sub(r'<[^>]+>', '', text) # Basic regex fallback for tags\n",
        "\n",
        "    # Normalize whitespace: replace multiple spaces/newlines/tabs with a single space\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    # Trim leading/trailing whitespace\n",
        "    text = text.strip()\n",
        "    # Optional: Remove control characters that might cause issues\n",
        "    text = re.sub(r'[\\x00-\\x1f\\x7f]', '', text)\n",
        "    return text\n",
        "\n",
        "def clean_amenities(text):\n",
        "    \"\"\"Cleans amenities text, preserving intended newlines.\"\"\"\n",
        "    if pd.isna(text) or text == '':\n",
        "        return ''\n",
        "    text = str(text)\n",
        "    lines = text.split('\\n')\n",
        "    # Clean whitespace from each line, keep non-empty lines\n",
        "    cleaned_lines = [' '.join(line.split()).strip() for line in lines if line.strip()]\n",
        "    return \"\\n\".join(cleaned_lines) # Re-join with single newline\n",
        "\n",
        "def extract_and_convert_numeric(value):\n",
        "    \"\"\"Extracts number from string and converts to int or float.\"\"\"\n",
        "    if pd.isna(value) or value == '':\n",
        "        return pd.NA # Use Pandas NA for missing numbers\n",
        "    # Remove common currency symbols, commas, etc.\n",
        "    cleaned_value = re.sub(r'[$,]', '', str(value))\n",
        "    # Find the first number-like pattern (integer or float, allows leading sign)\n",
        "    match = re.search(r'-?\\d+(\\.\\d+)?', cleaned_value)\n",
        "    if match:\n",
        "        num_str = match.group(0)\n",
        "        try:\n",
        "            if '.' in num_str:\n",
        "                return float(num_str)\n",
        "            else:\n",
        "                return int(num_str)\n",
        "        except ValueError:\n",
        "            logging.warning(f\"Could not convert extracted number string '{num_str}' to numeric.\")\n",
        "            return pd.NA # Conversion failed\n",
        "    else:\n",
        "        # If no number found, might be text like 'Contact Faculty'\n",
        "        logging.debug(f\"No numeric pattern found in value: '{value}'\")\n",
        "        return pd.NA\n",
        "\n",
        "# === Main Script Execution ===\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    logging.info(\"--- Data Cleaning Script Started ---\")\n",
        "\n",
        "    # --- 1. Mount Google Drive ---\n",
        "    try:\n",
        "        drive.mount('/content/drive')\n",
        "        logging.info(\"Google Drive mounted successfully.\")\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error mounting Google Drive: {e}. Please authorize access.\", exc_info=True)\n",
        "        exit()\n",
        "\n",
        "    # --- 2. Load Data (Attempting UTF-8 fix) ---\n",
        "    logging.info(f\"Attempting to load data from: {INPUT_CSV_FILE}\")\n",
        "    if not os.path.exists(INPUT_CSV_FILE):\n",
        "        logging.error(f\"Input file not found: {INPUT_CSV_FILE}\")\n",
        "        try:\n",
        "            logging.info(f\"Listing contents of '{DRIVE_BASE_PATH}': {os.listdir(DRIVE_BASE_PATH)}\")\n",
        "        except Exception as e_ls:\n",
        "            logging.error(f\"Could not list directory contents: {e_ls}\")\n",
        "        exit()\n",
        "\n",
        "    try:\n",
        "        # ** Try reading with UTF-8 first **\n",
        "        df = pd.read_csv(INPUT_CSV_FILE, encoding='utf-8')\n",
        "        logging.info(f\"Successfully loaded {len(df)} rows using UTF-8 encoding.\")\n",
        "    except UnicodeDecodeError:\n",
        "        logging.warning(\"UTF-8 decoding failed. Trying with 'latin-1' and will apply Mojibake fix later.\")\n",
        "        try:\n",
        "             df = pd.read_csv(INPUT_CSV_FILE, encoding='latin-1')\n",
        "             logging.info(f\"Successfully loaded {len(df)} rows using latin-1 encoding (Mojibake fix needed).\")\n",
        "             needs_mojibake_fix = True\n",
        "        except Exception as e_load:\n",
        "            logging.error(f\"Error loading CSV with fallback encoding: {e_load}\", exc_info=True)\n",
        "            exit()\n",
        "    except Exception as e_load:\n",
        "        logging.error(f\"Generic error loading CSV: {e_load}\", exc_info=True)\n",
        "        exit()\n",
        "    else:\n",
        "         needs_mojibake_fix = False # UTF-8 worked, likely no fix needed unless file itself is corrupted\n",
        "\n",
        "    logging.info(\"Initial DataFrame info:\")\n",
        "    df.info()\n",
        "    logging.info(\"Sample rows before cleaning:\")\n",
        "    logging.info(df.head())\n",
        "\n",
        "\n",
        "    # --- 3. Fix Mojibake (if needed) ---\n",
        "    if needs_mojibake_fix:\n",
        "        logging.info(\"Applying Mojibake fix (assuming UTF-8 misinterpreted as latin-1)...\")\n",
        "        mojibake_pattern = r'[ØÙÖÝ]' # Common starting characters in this type of Mojibake\n",
        "        applied_fix_count = 0\n",
        "        for col in TEXT_COLUMNS_TO_CLEAN:\n",
        "            if col in df.columns and df[col].dtype == 'object':\n",
        "                # Check more thoroughly if fix is needed for this column\n",
        "                if df[col].astype(str).str.contains(mojibake_pattern, regex=True, na=False).any():\n",
        "                     logging.info(f\"Applying Mojibake fix to column: {col}\")\n",
        "                     df[col] = df[col].apply(fix_mojibake)\n",
        "                     applied_fix_count += 1\n",
        "                else:\n",
        "                     logging.debug(f\"No Mojibake pattern detected in column: {col}\")\n",
        "        if applied_fix_count == 0:\n",
        "             logging.warning(\"Loaded with latin-1, but no common Mojibake patterns detected. Check data manually.\")\n",
        "        logging.info(\"Mojibake fix attempt complete.\")\n",
        "        logging.info(\"Sample rows after Mojibake fix attempt:\")\n",
        "        logging.info(df.head())\n",
        "\n",
        "    # --- 4. Standardize Missing Values ---\n",
        "    logging.info(f\"Standardizing missing values (replacing {MISSING_MARKERS}) with empty strings...\")\n",
        "    num_cols_processed = 0\n",
        "    for col in df.select_dtypes(include='object').columns: # Only process object (usually string) columns\n",
        "        # Create a boolean mask for values to replace\n",
        "        mask = df[col].isin(MISSING_MARKERS)\n",
        "        if mask.any():\n",
        "             logging.debug(f\"Replacing missing markers in column: {col}\")\n",
        "             df[col] = df[col].replace(MISSING_MARKERS, pd.NA) # Replace with Pandas NA\n",
        "             num_cols_processed += 1\n",
        "\n",
        "    df = df.fillna('') # Fill all NA values (from replace or original) with empty string\n",
        "    logging.info(f\"Standardized missing values in {num_cols_processed} object columns.\")\n",
        "\n",
        "\n",
        "    # --- 5. Clean Text Fields ---\n",
        "    logging.info(\"Cleaning whitespace and special characters in text columns...\")\n",
        "    for col in TEXT_COLUMNS_TO_CLEAN:\n",
        "        if col in df.columns and df[col].dtype == 'object':\n",
        "             logging.debug(f\"Cleaning text column: {col}\")\n",
        "             if col == 'Amenities':\n",
        "                  df[col] = df[col].apply(clean_amenities)\n",
        "             else:\n",
        "                  df[col] = df[col].apply(clean_text)\n",
        "    logging.info(\"Text cleaning complete.\")\n",
        "\n",
        "\n",
        "    # --- 6. Clean and Convert Numeric Fields ---\n",
        "    logging.info(\"Converting specified columns to numeric types...\")\n",
        "    for col in NUMERIC_COLUMNS:\n",
        "        if col in df.columns:\n",
        "            logging.debug(f\"Converting column to numeric: {col}\")\n",
        "            original_dtype = df[col].dtype\n",
        "            df[col] = df[col].apply(extract_and_convert_numeric)\n",
        "            # Attempt conversion to nullable Int64 if appropriate\n",
        "            try:\n",
        "                 # Check if all non-NA values are integers after conversion\n",
        "                 if df[col].dropna().apply(lambda x: float(x).is_integer()).all():\n",
        "                     df[col] = df[col].astype('Int64') # Use Pandas nullable integer type\n",
        "            except Exception:\n",
        "                 # If conversion fails or column contains floats, leave as float/object\n",
        "                 logging.debug(f\"Column {col} kept as float or object after conversion attempt.\")\n",
        "                 pass\n",
        "            logging.debug(f\"Column '{col}' type changed from {original_dtype} to {df[col].dtype}\")\n",
        "        else:\n",
        "             logging.warning(f\"Numeric column '{col}' not found in DataFrame.\")\n",
        "    logging.info(\"Numeric conversion complete.\")\n",
        "\n",
        "\n",
        "    # --- 7. Final Review ---\n",
        "    logging.info(\"Cleaned DataFrame info:\")\n",
        "    df.info()\n",
        "    logging.info(\"Sample rows after all cleaning:\")\n",
        "    logging.info(df.head())\n",
        "    logging.info(\"Checking for columns that are now entirely empty/NA:\")\n",
        "    all_na_cols = df.columns[df.isna().all()].tolist()\n",
        "    if all_na_cols:\n",
        "         logging.info(f\"Columns with all NA values: {all_na_cols}\")\n",
        "    else:\n",
        "         logging.info(\"No columns found with all NA values.\")\n",
        "\n",
        "\n",
        "    # --- 8. Save Cleaned Data ---\n",
        "    logging.info(f\"Attempting to save cleaned data to: {OUTPUT_CSV_FILE}\")\n",
        "    try:\n",
        "        # Use 'utf-8-sig' to include BOM for better Excel compatibility with UTF-8\n",
        "        df.to_csv(OUTPUT_CSV_FILE, index=False, encoding='utf-8-sig')\n",
        "        logging.info(f\"Cleaned data successfully saved to {OUTPUT_CSV_FILE}\")\n",
        "        logging.info(\"You can find the file in your Google Drive.\")\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error saving cleaned CSV: {e}\", exc_info=True)\n",
        "\n",
        "    logging.info(\"--- Data Cleaning Script Finished ---\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LQHiugI3GEex",
        "outputId": "fcaa97c6-1c0e-494c-8808-3aa041d17059"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 17581 entries, 0 to 17580\n",
            "Data columns (total 23 columns):\n",
            " #   Column                   Non-Null Count  Dtype  \n",
            "---  ------                   --------------  -----  \n",
            " 0   University               17581 non-null  object \n",
            " 1   Category                 17581 non-null  object \n",
            " 2   Year Built               17581 non-null  object \n",
            " 3   Description              17581 non-null  object \n",
            " 4   Location                 17532 non-null  object \n",
            " 5   Phone                    17581 non-null  object \n",
            " 6   Email                    17581 non-null  object \n",
            " 7   Coordinator              15303 non-null  object \n",
            " 8   Amenities                17581 non-null  object \n",
            " 9   Detail Page URL          17581 non-null  object \n",
            " 10  Program Category         17353 non-null  object \n",
            " 11  Faculty                  17353 non-null  object \n",
            " 12  Program Name             17340 non-null  object \n",
            " 13  Program Description      16091 non-null  object \n",
            " 14  Years Of Study           13298 non-null  float64\n",
            " 15  Number Of Semesters      11156 non-null  float64\n",
            " 16  Fee In USD               14958 non-null  float64\n",
            " 17  Fee In EGP               3333 non-null   float64\n",
            " 18  Prerequisites            4106 non-null   object \n",
            " 19  Credit Hours             2753 non-null   float64\n",
            " 20  Max Study Years          10907 non-null  float64\n",
            " 21  Affiliated Universities  32 non-null     object \n",
            " 22  Semesters Abroad         20 non-null     float64\n",
            "dtypes: float64(7), object(16)\n",
            "memory usage: 3.1+ MB\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 17581 entries, 0 to 17580\n",
            "Data columns (total 23 columns):\n",
            " #   Column                   Non-Null Count  Dtype \n",
            "---  ------                   --------------  ----- \n",
            " 0   University               17581 non-null  object\n",
            " 1   Category                 17581 non-null  object\n",
            " 2   Year Built               17180 non-null  Int64 \n",
            " 3   Description              17581 non-null  object\n",
            " 4   Location                 17581 non-null  object\n",
            " 5   Phone                    17581 non-null  object\n",
            " 6   Email                    17581 non-null  object\n",
            " 7   Coordinator              17581 non-null  object\n",
            " 8   Amenities                17581 non-null  object\n",
            " 9   Detail Page URL          17581 non-null  object\n",
            " 10  Program Category         17581 non-null  object\n",
            " 11  Faculty                  17581 non-null  object\n",
            " 12  Program Name             17581 non-null  object\n",
            " 13  Program Description      17581 non-null  object\n",
            " 14  Years Of Study           13298 non-null  Int64 \n",
            " 15  Number Of Semesters      11156 non-null  Int64 \n",
            " 16  Fee In USD               14958 non-null  object\n",
            " 17  Fee In EGP               3333 non-null   object\n",
            " 18  Prerequisites            17581 non-null  object\n",
            " 19  Credit Hours             2753 non-null   Int64 \n",
            " 20  Max Study Years          10907 non-null  Int64 \n",
            " 21  Affiliated Universities  17581 non-null  object\n",
            " 22  Semesters Abroad         20 non-null     Int64 \n",
            "dtypes: Int64(6), object(17)\n",
            "memory usage: 3.2+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "from google.colab import drive\n",
        "import os\n",
        "import logging\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter # Import the splitter\n",
        "\n",
        "# === Configuration ===\n",
        "# Configure logging\n",
        "LOG_FILE_CHUNK = 'text_chunking.log'\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(levelname)s - [%(funcName)s] %(message)s',\n",
        "    handlers=[\n",
        "        logging.FileHandler(LOG_FILE_CHUNK, mode='w', encoding='utf-8'),\n",
        "        logging.StreamHandler()\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Define file paths in Google Drive\n",
        "DRIVE_BASE_PATH = '/content/drive/MyDrive/Web Scraping /'\n",
        "INPUT_CLEANED_CSV = os.path.join(DRIVE_BASE_PATH, 'Cleaned_File.csv')\n",
        "OUTPUT_CHUNKS_CSV = os.path.join(DRIVE_BASE_PATH, 'egypt_institutions_chunks.csv') # File to save chunks\n",
        "\n",
        "# Chunking Parameters (adjust based on your target model and experiments)\n",
        "# RecursiveCharacterTextSplitter uses character count by default\n",
        "CHUNK_SIZE = 800  # Max characters per chunk\n",
        "CHUNK_OVERLAP = 100 # Characters overlap between consecutive chunks\n",
        "\n",
        "# === Helper Function ===\n",
        "\n",
        "def format_document_text(row):\n",
        "    \"\"\"Combines relevant columns from a row into a single text passage.\"\"\"\n",
        "    text_parts = []\n",
        "\n",
        "    # --- University Info ---\n",
        "    text_parts.append(f\"University Name: {row.get('Name', 'N/A')}\")\n",
        "    if row.get('Category'): text_parts.append(f\"Category: {row.get('Category')}\")\n",
        "    if row.get('Year Built'): text_parts.append(f\"Established: {row.get('Year Built')}\")\n",
        "    if row.get('Location'): text_parts.append(f\"Location: {row.get('Location')}\")\n",
        "    if row.get('Description'): text_parts.append(f\"\\nUniversity Description: {row.get('Description')}\")\n",
        "    if row.get('Amenities') and row.get('Amenities') != 'Not Found' and row.get('Amenities') != 'None Listed':\n",
        "        # Format amenities nicely if present\n",
        "        amenities_list = row.get('Amenities', '').split('\\n')\n",
        "        if amenities_list:\n",
        "            text_parts.append(\"\\nAmenities:\")\n",
        "            for amenity in amenities_list:\n",
        "                 text_parts.append(f\"- {amenity}\")\n",
        "\n",
        "    # --- Program Info (only if a program name exists for this row) ---\n",
        "    if row.get('Program Name') and row.get('Program Name') not in ['N/A', 'Not Found']:\n",
        "        text_parts.append(\"\\n---\\nProgram Details:\") # Separator\n",
        "        if row.get('Program Category'): text_parts.append(f\"Program Category: {row.get('Program Category')}\")\n",
        "        if row.get('Faculty'): text_parts.append(f\"Faculty: {row.get('Faculty')}\")\n",
        "        text_parts.append(f\"Program Name: {row.get('Program Name')}\")\n",
        "        if row.get('Program Description'): text_parts.append(f\"Program Description: {row.get('Program Description')}\")\n",
        "        if row.get('Years Of Study'): text_parts.append(f\"Years of Study: {row.get('Years Of Study')}\")\n",
        "        if row.get('Number Of Semesters'): text_parts.append(f\"Semesters: {row.get('Number Of Semesters')}\")\n",
        "        if row.get('Credit Hours'): text_parts.append(f\"Credit Hours: {row.get('Credit Hours')}\")\n",
        "        if row.get('Max Study Years'): text_parts.append(f\"Max Study Years: {row.get('Max Study Years')}\")\n",
        "        if row.get('Semesters Abroad'): text_parts.append(f\"Semesters Abroad: {row.get('Semesters Abroad')}\")\n",
        "\n",
        "        fees = []\n",
        "        if row.get('Fee In USD') and str(row.get('Fee In USD')).strip(): fees.append(f\"Fee (USD): {row.get('Fee In USD')}\")\n",
        "        if row.get('Fee In EGP') and str(row.get('Fee In EGP')).strip(): fees.append(f\"Fee (EGP): {row.get('Fee In EGP')}\")\n",
        "        if fees: text_parts.append(\", \".join(fees))\n",
        "\n",
        "        if row.get('Prerequisites'): text_parts.append(f\"Prerequisites: {row.get('Prerequisites')}\")\n",
        "        if row.get('Affiliated Universities'): text_parts.append(f\"Affiliated Universities: {row.get('Affiliated Universities')}\")\n",
        "\n",
        "    # --- Contact Info (Optional, add if useful context) ---\n",
        "    # if row.get('Phone'): text_parts.append(f\"Phone: {row.get('Phone')}\")\n",
        "    # if row.get('Email'): text_parts.append(f\"Email: {row.get('Email')}\")\n",
        "    # if row.get('Coordinator'): text_parts.append(f\"Coordinator: {row.get('Coordinator')}\")\n",
        "\n",
        "    return \"\\n\".join(filter(None, text_parts)) # Join non-empty parts with newline\n",
        "\n",
        "# === Main Script Execution ===\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    logging.info(\"--- Text Chunking Script Started ---\")\n",
        "\n",
        "    # --- 1. Mount Google Drive ---\n",
        "    try:\n",
        "        drive.mount('/content/drive')\n",
        "        logging.info(\"Google Drive mounted successfully.\")\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error mounting Google Drive: {e}. Please authorize access.\", exc_info=True)\n",
        "        exit()\n",
        "\n",
        "    # --- 2. Load Cleaned Data ---\n",
        "    logging.info(f\"Loading cleaned data from: {INPUT_CLEANED_CSV}\")\n",
        "    if not os.path.exists(INPUT_CLEANED_CSV):\n",
        "        logging.error(f\"Input file not found: {INPUT_CLEANED_CSV}\")\n",
        "        exit()\n",
        "    try:\n",
        "        df_cleaned = pd.read_csv(INPUT_CLEANED_CSV, encoding='utf-8-sig') # Read the cleaned file\n",
        "        # Handle potential empty strings read as NaN after cleaning/saving\n",
        "        df_cleaned = df_cleaned.fillna('')\n",
        "        logging.info(f\"Successfully loaded {len(df_cleaned)} rows from cleaned file.\")\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error loading cleaned CSV: {e}\", exc_info=True)\n",
        "        exit()\n",
        "\n",
        "    # --- 3. Initialize Text Splitter ---\n",
        "    logging.info(f\"Initializing RecursiveCharacterTextSplitter with chunk_size={CHUNK_SIZE}, chunk_overlap={CHUNK_OVERLAP}\")\n",
        "    text_splitter = RecursiveCharacterTextSplitter(\n",
        "        chunk_size=CHUNK_SIZE,\n",
        "        chunk_overlap=CHUNK_OVERLAP,\n",
        "        length_function=len, # Use character length\n",
        "        is_separator_regex=False, # Treat separators literally\n",
        "        separators=[\"\\n\\n\", \"\\n\", \". \", \", \", \" \", \"\"] # Define splitting hierarchy\n",
        "    )\n",
        "\n",
        "    # --- 4. Process Rows and Create Chunks ---\n",
        "    all_chunks_data = []\n",
        "    logging.info(\"Starting chunking process...\")\n",
        "    total_rows = len(df_cleaned)\n",
        "\n",
        "    for index, row in df_cleaned.iterrows():\n",
        "        if index % 100 == 0: # Log progress every 100 rows\n",
        "             logging.info(f\"Processing row {index + 1} of {total_rows}...\")\n",
        "\n",
        "        # Create the combined text document for this row\n",
        "        document_text = format_document_text(row)\n",
        "\n",
        "        if not document_text.strip():\n",
        "             logging.warning(f\"Skipping row {index + 1} (University: {row.get('Name', 'N/A')}) due to empty combined text.\")\n",
        "             continue\n",
        "\n",
        "        # Define metadata for these chunks\n",
        "        metadata = {\n",
        "            'university_name': row.get('Name', ''),\n",
        "            'program_name': row.get('Program Name', ''), # Will be empty/NA for rows without programs\n",
        "            'faculty': row.get('Faculty', ''),\n",
        "            'source_url': row.get('Detail Page URL', ''),\n",
        "            'original_row_index': index # Link back to original cleaned row if needed\n",
        "        }\n",
        "\n",
        "        # Split the document text into chunks\n",
        "        try:\n",
        "            chunks = text_splitter.split_text(document_text)\n",
        "        except Exception as e_split:\n",
        "             logging.error(f\"Error splitting text for row {index+1} (University: {metadata['university_name']}): {e_split}\", exc_info=True)\n",
        "             chunks = [] # Handle error gracefully, maybe add error marker?\n",
        "\n",
        "        # Store each chunk with its metadata\n",
        "        for i, chunk_text in enumerate(chunks):\n",
        "            chunk_data = {\n",
        "                'chunk_text': chunk_text,\n",
        "                'chunk_sequence': i + 1, # Sequence number of chunk within its document\n",
        "                **metadata # Add all metadata keys\n",
        "            }\n",
        "            all_chunks_data.append(chunk_data)\n",
        "\n",
        "    logging.info(f\"Chunking complete. Generated {len(all_chunks_data)} chunks from {total_rows} input rows.\")\n",
        "\n",
        "    # --- 5. Save Chunks to CSV ---\n",
        "    if all_chunks_data:\n",
        "        df_chunks = pd.DataFrame(all_chunks_data)\n",
        "        logging.info(f\"Attempting to save {len(df_chunks)} chunks to: {OUTPUT_CHUNKS_CSV}\")\n",
        "        try:\n",
        "            # Define order of columns for the output chunk file\n",
        "            chunk_fieldnames = [\n",
        "                'university_name', 'faculty', 'program_name', 'chunk_sequence',\n",
        "                'chunk_text', 'source_url', 'original_row_index'\n",
        "            ]\n",
        "            df_chunks = df_chunks[chunk_fieldnames] # Reorder columns\n",
        "            df_chunks.to_csv(OUTPUT_CHUNKS_CSV, index=False, encoding='utf-8-sig')\n",
        "            logging.info(f\"Chunks successfully saved to {OUTPUT_CHUNKS_CSV}\")\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Error saving chunks CSV: {e}\", exc_info=True)\n",
        "    else:\n",
        "        logging.warning(\"No chunks were generated to save.\")\n",
        "\n",
        "    logging.info(\"--- Text Chunking Script Finished ---\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x4DnZwM2Mp_k",
        "outputId": "870a93af-0338-4b6c-dbfa-d02b605274c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NHqv-mlDo40S"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}